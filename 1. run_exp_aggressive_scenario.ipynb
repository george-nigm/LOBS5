{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd /app"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os\n",
    "import sys\n",
    "\n",
    "os.environ[\"XLA_PYTHON_CLIENT_PREALLOCATE\"] = \"false\"\n",
    "\n",
    "import torch\n",
    "torch.multiprocessing.set_start_method('spawn')\n",
    "\n",
    "import jax\n",
    "from lob.encoding import Vocab, Message_Tokenizer\n",
    "\n",
    "from lob import inference_no_errcorr as inference\n",
    "from lob.init_train import init_train_state, load_checkpoint, load_metadata, load_args_from_checkpoint\n",
    "\n",
    "from lob import inference_no_errcorr as inference\n",
    "import lob.encoding as encoding\n",
    "import preproc as preproc\n",
    "\n",
    "import jax.numpy as jnp\n",
    "import numpy as onp\n",
    "\n",
    "from pathlib import Path\n",
    "import os\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "\n",
    "def create_next_experiment_folder(save_folder: str) -> Path:\n",
    "    base = Path(save_folder)\n",
    "    if not base.exists():\n",
    "        raise FileNotFoundError(f\"Каталога {save_folder!r} не существует\")\n",
    "\n",
    "    max_idx = 0\n",
    "    for entry in base.iterdir():\n",
    "        if entry.is_dir() and entry.name.startswith(\"exp_\"):\n",
    "            parts = entry.name.split(\"_\")\n",
    "            if len(parts) >= 2 and parts[1].isdigit():\n",
    "                idx = int(parts[1])\n",
    "                max_idx = max(max_idx, idx)\n",
    "\n",
    "    next_idx = max_idx + 1\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    new_folder_name = f\"exp_{next_idx}_{timestamp}\"\n",
    "    new_folder = base / new_folder_name\n",
    "    new_folder.mkdir()\n",
    "    return new_folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# == Parameters for Config == #\n",
    "\n",
    "save_folder = 'data_saved/' # - need to scan folders in this folder and create next folder 2,3,...,99\n",
    "\n",
    "batch_size = 4\n",
    "n_samples = 20\n",
    "\n",
    "n_gen_msgs = 50 # how many messages to generate into the future\n",
    "midprice_step_size = 1\n",
    "\n",
    "num_insertions = 20\n",
    "num_coolings = 40\n",
    "\n",
    "EVENT_TYPE_i = 4\n",
    "DIRECTION_i = 0\n",
    "order_volume = 75\n",
    "\n",
    "# ======== #\n",
    "\n",
    "# scale down to single GPU, single sample inference\n",
    "bsz = 2 #1, 10\n",
    "num_devices = 3\n",
    "\n",
    "n_messages = 500  # length of input sequence to model\n",
    "book_dim = 501 #b_enc.shape[1] 500+1=501\n",
    "n_vol_series = 500\n",
    "sample_top_n = -1\n",
    "\n",
    "model_size = 'large'\n",
    "data_dir ='data/test_set/'\n",
    "sample_all = False # action='store_true'\n",
    "stock = 'GOOG'  # 'GOOG', 'INTC'\n",
    "\n",
    "tick_size = 100\n",
    "sample_all = False\n",
    "rng_seed = 42\n",
    "\n",
    "\n",
    "# ======== #\n",
    "\n",
    "v = Vocab()\n",
    "n_classes = len(v)\n",
    "seq_len = n_messages * Message_Tokenizer.MSG_LEN\n",
    "book_seq_len = n_messages\n",
    "\n",
    "n_eval_messages = n_gen_msgs\n",
    "eval_seq_len = n_eval_messages * Message_Tokenizer.MSG_LEN\n",
    "\n",
    "rng = jax.random.key(rng_seed)\n",
    "rng, rng_ = jax.random.split(rng)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_folder = create_next_experiment_folder(save_folder)\n",
    "print(\"Created new experiment directory:\", save_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if stock == 'GOOG':\n",
    "    # ckpt_path = './checkpoints/treasured-leaf-149_84yhvzjt/' # 0.5 y GOOG, (full model)\n",
    "    ckpt_path = './checkpoints/denim-elevator-754_czg1ss71/' # large model\n",
    "    # ckpt_path = './checkpoints/stilted-deluge-759_8g3vqor4'  # small model\n",
    "elif stock == 'INTC':\n",
    "    # ckpt_path = './checkpoints/pleasant-cherry-152_i6h5n74c/' # 0.5 y INTC, (full model)\n",
    "    ckpt_path = './checkpoints/eager-sea-755_2rw1ofs3/'  # large model\n",
    "else:\n",
    "    raise ValueError(f'stock {stock} not recognized')\n",
    "\n",
    "print('Loading metadata:', ckpt_path)\n",
    "args_ckpt = load_metadata(ckpt_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load train state from disk\n",
    "\n",
    "print('Initializing model...')\n",
    "new_train_state, model_cls = init_train_state(\n",
    "    args_ckpt,\n",
    "    n_classes=n_classes,\n",
    "    seq_len=seq_len,\n",
    "    book_dim=book_dim,\n",
    "    book_seq_len=book_seq_len,\n",
    ")\n",
    "\n",
    "print('\\nLoading model checkpoint...')\n",
    "ckpt = load_checkpoint(\n",
    "    new_train_state,\n",
    "    ckpt_path,\n",
    "    train=False,\n",
    ")\n",
    "state = ckpt['model']\n",
    "\n",
    "model = model_cls(training=False, step_rescale=1.0)\n",
    "\n",
    "param_count = sum(x.size for x in jax.tree_leaves(state.params))\n",
    "print('param count:', param_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scale down to single GPU, single sample inference\n",
    "args_ckpt.bsz = bsz #1, 10\n",
    "args_ckpt.num_devices = num_devices\n",
    "\n",
    "batchnorm = args_ckpt.batchnorm\n",
    "\n",
    "data_dir = data_dir + stock\n",
    "print(f\"Directory Path: {data_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = Path(data_dir)\n",
    "Path(data_dir).mkdir(parents=True, exist_ok=True)\n",
    "folder_path = Path(data_dir)\n",
    "file_count = len([f for f in folder_path.iterdir() if f.is_file()])\n",
    "print(f\"There are {file_count} files in the folder {str(data_dir)}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(n_messages, n_eval_messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import os\n",
    "\n",
    "# Print current working directory to help verify the path\n",
    "print(f\"Current working directory: {os.getcwd()}\")\n",
    "\n",
    "# Use relative path to data/test_set/GOOG\n",
    "data_dir = Path(\"data/test_set/GOOG\")\n",
    "\n",
    "try:\n",
    "    Path(data_dir).mkdir(parents=True, exist_ok=True)\n",
    "    print(f\"Successfully created or verified directory: {data_dir}\")\n",
    "    \n",
    "    file_count = len([f for f in Path(data_dir).iterdir() if f.is_file()])\n",
    "    print(f\"There are {file_count} files in the folder {data_dir}.\")\n",
    "except Exception as e:\n",
    "    print(f\"Error: {str(e)}\")\n",
    "\n",
    "ds = inference.get_dataset(data_dir, n_messages, n_eval_messages)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# check 1 by 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(save_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inference.run_generation_scenario(\n",
    "    n_samples, \n",
    "    batch_size,\n",
    "    ds,\n",
    "    rng,\n",
    "    seq_len,\n",
    "    n_messages,\n",
    "    n_gen_msgs,\n",
    "    state,\n",
    "    model,\n",
    "    batchnorm,\n",
    "    v.ENCODING,\n",
    "    stock,\n",
    "    n_vol_series,\n",
    "    save_folder,\n",
    "    tick_size,\n",
    "    sample_top_n,\n",
    "    sample_all,\n",
    "    num_insertions,\n",
    "    num_coolings,\n",
    "    midprice_step_size,\n",
    "    EVENT_TYPE_i, \n",
    "    DIRECTION_i, \n",
    "    order_volume\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
