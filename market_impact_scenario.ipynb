{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/app\n"
     ]
    }
   ],
   "source": [
    "%cd /app"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Type handler registry overriding type \"<class 'float'>\" collision on scalar\n",
      "WARNING:absl:Type handler registry overriding type \"<class 'bytes'>\" collision on scalar\n",
      "WARNING:absl:Type handler registry overriding type \"<class 'numpy.number'>\" collision on scalar\n",
      "2025-03-12 22:33:30.094854: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import os\n",
    "import sys\n",
    "\n",
    "os.environ[\"XLA_PYTHON_CLIENT_PREALLOCATE\"] = \"false\"\n",
    "\n",
    "import torch\n",
    "torch.multiprocessing.set_start_method('spawn')\n",
    "\n",
    "import jax\n",
    "from lob.encoding import Vocab, Message_Tokenizer\n",
    "\n",
    "from lob import inference_no_errcorr as inference\n",
    "from lob.init_train import init_train_state, load_checkpoint, load_metadata, load_args_from_checkpoint\n",
    "\n",
    "from lob import inference_no_errcorr as inference\n",
    "import lob.encoding as encoding\n",
    "import preproc as preproc\n",
    "\n",
    "import jax.numpy as jnp\n",
    "import numpy as onp\n",
    "\n",
    "from pathlib import Path\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_folder = 'data_saved/'\n",
    "batch_size =4\n",
    "model_size = 'large'\n",
    "data_dir ='data/test_set/'\n",
    "rng_seed = 42\n",
    "sample_all = False # action='store_true'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "stock = 'GOOG'  # 'GOOG', 'INTC'\n",
    "n_gen_msgs = 500 # how many messages to generate into the future\n",
    "n_samples = 32\n",
    "tick_size = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_messages = 500  # length of input sequence to model\n",
    "# batch_size = batch_size\n",
    "\n",
    "v = Vocab()\n",
    "n_classes = len(v)\n",
    "seq_len = n_messages * Message_Tokenizer.MSG_LEN\n",
    "book_dim = 501 #b_enc.shape[1]\n",
    "book_seq_len = n_messages\n",
    "\n",
    "n_eval_messages = n_gen_msgs  # how many to load from dataset\n",
    "eval_seq_len = n_eval_messages * Message_Tokenizer.MSG_LEN\n",
    "\n",
    "rng = jax.random.key(rng_seed)\n",
    "rng, rng_ = jax.random.split(rng)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "if stock == 'GOOG':\n",
    "    # ckpt_path = './checkpoints/treasured-leaf-149_84yhvzjt/' # 0.5 y GOOG, (full model)\n",
    "    ckpt_path = './checkpoints/denim-elevator-754_czg1ss71/' # large model\n",
    "    # ckpt_path = './checkpoints/stilted-deluge-759_8g3vqor4'  # small model\n",
    "elif stock == 'INTC':\n",
    "    # ckpt_path = './checkpoints/pleasant-cherry-152_i6h5n74c/' # 0.5 y INTC, (full model)\n",
    "    ckpt_path = './checkpoints/eager-sea-755_2rw1ofs3/'  # large model\n",
    "else:\n",
    "    raise ValueError(f'stock {stock} not recognized')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading metadata: ./checkpoints/denim-elevator-754_czg1ss71/\n"
     ]
    }
   ],
   "source": [
    "print('Loading metadata:', ckpt_path)\n",
    "args_ckpt = load_metadata(ckpt_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scale down to single GPU, single sample inference\n",
    "args_ckpt.bsz = 1 #1, 10\n",
    "args_ckpt.num_devices = 1\n",
    "\n",
    "batchnorm = args_ckpt.batchnorm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing model...\n",
      "configuring standard optimization setup\n",
      "[*] Trainable Parameters: 35776312\n",
      "\n",
      "Loading model checkpoint...\n",
      "param count: 35776312\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_278913/2594640255.py:22: DeprecationWarning: jax.tree_leaves is deprecated: use jax.tree.leaves (jax v0.4.25 or newer) or jax.tree_util.tree_leaves (any JAX version).\n",
      "  param_count = sum(x.size for x in jax.tree_leaves(state.params))\n"
     ]
    }
   ],
   "source": [
    "# load train state from disk\n",
    "\n",
    "print('Initializing model...')\n",
    "new_train_state, model_cls = init_train_state(\n",
    "    args_ckpt,\n",
    "    n_classes=n_classes,\n",
    "    seq_len=seq_len,\n",
    "    book_dim=book_dim,\n",
    "    book_seq_len=book_seq_len,\n",
    ")\n",
    "\n",
    "print('\\nLoading model checkpoint...')\n",
    "ckpt = load_checkpoint(\n",
    "    new_train_state,\n",
    "    ckpt_path,\n",
    "    train=False,\n",
    ")\n",
    "state = ckpt['model']\n",
    "\n",
    "model = model_cls(training=False, step_rescale=1.0)\n",
    "\n",
    "param_count = sum(x.size for x in jax.tree_leaves(state.params))\n",
    "print('param count:', param_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory Path: data/test_set/GOOG\n"
     ]
    }
   ],
   "source": [
    "data_dir = data_dir + stock\n",
    "# data_dir = data_dir + 'GOOG'\n",
    "print(f\"Directory Path: {data_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 36 files in the folder data/test_set/GOOG.\n"
     ]
    }
   ],
   "source": [
    "# data_dir = Path.home() / \"data/test_set/GOOG\"\n",
    "# Or use a relative path from current working directory\n",
    "# data_dir = Path(\"data/test_set/GOOG\")\n",
    "data_dir = Path(data_dir)\n",
    "\n",
    "Path(data_dir).mkdir(parents=True, exist_ok=True)\n",
    "folder_path = Path(data_dir)\n",
    "file_count = len([f for f in folder_path.iterdir() if f.is_file()])\n",
    "print(f\"There are {file_count} files in the folder {str(data_dir)}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500 500\n"
     ]
    }
   ],
   "source": [
    "print(n_messages, n_eval_messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current working directory: /app\n",
      "Successfully created or verified directory: data/test_set/GOOG\n",
      "There are 36 files in the folder data/test_set/GOOG.\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import os\n",
    "\n",
    "# Print current working directory to help verify the path\n",
    "print(f\"Current working directory: {os.getcwd()}\")\n",
    "\n",
    "# Use relative path to data/test_set/GOOG\n",
    "data_dir = Path(\"data/test_set/GOOG\")\n",
    "\n",
    "try:\n",
    "    Path(data_dir).mkdir(parents=True, exist_ok=True)\n",
    "    print(f\"Successfully created or verified directory: {data_dir}\")\n",
    "    \n",
    "    file_count = len([f for f in Path(data_dir).iterdir() if f.is_file()])\n",
    "    print(f\"There are {file_count} files in the folder {data_dir}.\")\n",
    "except Exception as e:\n",
    "    print(f\"Error: {str(e)}\")\n",
    "\n",
    "ds = inference.get_dataset(data_dir, n_messages, n_eval_messages)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# check 1 by 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "m_seq: (Array([ 1005, 12010, 12007, ...,   858,   838,   719], dtype=int32), Array([ 1003, 12009, 12008, ...,     2,     2,     2], dtype=int32))\n",
      "\n",
      "\n",
      "b_seq_pv: (memmap([[     0, 884500,    225, ...,    707, 883400,    200],\n",
      "        [     0, 884500,    225, ...,    707, 883400,    200],\n",
      "        [     0, 884500,    225, ...,    707, 883400,    200],\n",
      "        ...,\n",
      "        [     0, 884600,    325, ...,    200, 883500,    100],\n",
      "        [     0, 884600,    325, ...,    200, 883500,    100],\n",
      "        [     0, 884600,    325, ...,    200, 883500,    100]]), memmap([[     0, 874900,    179, ...,   1297, 873900,    841],\n",
      "        [     0, 874900,    179, ...,   1297, 873900,    841],\n",
      "        [     0, 874900,    179, ...,   1297, 873900,    841],\n",
      "        ...,\n",
      "        [     0, 874700,    200, ...,    889, 873700,    947],\n",
      "        [     0, 874700,    100, ...,    889, 873700,    947],\n",
      "        [     0, 874700,    100, ...,    889, 873700,    947]]))\n",
      "\n",
      "\n",
      "msg_seq_raw: (Array([[815620622,         3,         1, ...,       100,     53060,\n",
      "        276711069],\n",
      "       [815626126,         1,         1, ...,     -9999,     -9999,\n",
      "            -9999],\n",
      "       [815628422,         1,         0, ...,     -9999,     -9999,\n",
      "            -9999],\n",
      "       ...,\n",
      "       [815784670,         3,         0, ...,       200,     53065,\n",
      "        993635964],\n",
      "       [815779526,         3,         1, ...,       100,     53065,\n",
      "        645717081],\n",
      "       [815782734,         3,         0, ...,       100,     53065,\n",
      "        855835716]], dtype=int32), Array([[637822774,         1,         0, ...,     -9999,     -9999,\n",
      "            -9999],\n",
      "       [637819270,         3,         1, ...,       100,     49828,\n",
      "        979461959],\n",
      "       [637819102,         3,         1, ...,       100,     49828,\n",
      "        978347552],\n",
      "       ...,\n",
      "       [638101450,         3,         0, ...,       100,     49838,\n",
      "        942197798],\n",
      "       [638039618,         3,         0, ...,       100,     49837,\n",
      "        232750252],\n",
      "       [638105798,         1,         1, ...,     -9999,     -9999,\n",
      "            -9999]], dtype=int32))\n",
      "\n",
      "\n",
      "book_l2_init: (array([884500,    225, 884300,    400, 884600,    225, 884200,    250,\n",
      "       884700,    353, 884100,    625, 884800,    349, 884000,    325,\n",
      "       884900,    925, 883900,    625, 885000,   1900, 883800,   1122,\n",
      "       885100,    300, 883700,    100, 885200,    300, 883600,    100,\n",
      "       885300,    300, 883500,    100, 885400,    707, 883400,    200]), array([874900,    179, 874800,    381, 875000,   1168, 874700,    482,\n",
      "       875100,   1738, 874600,    427, 875200,   1488, 874500,   1182,\n",
      "       875300,    510, 874400,   1086, 875400,   1100, 874300,    983,\n",
      "       875500,   1050, 874200,    400, 875600,    910, 874100,    250,\n",
      "       875700,    445, 874000,    557, 875800,   1297, 873900,    841]))\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "batch_i = [4497, 6855]\n",
    "m_seq, _, b_seq_pv, msg_seq_raw, book_l2_init = ds[batch_i]\n",
    "\n",
    "# i_sample = 4497\n",
    "# m_seq, _, b_seq_pv, msg_seq_raw, book_l2_init = ds[i_sample]\n",
    "\n",
    "\n",
    "print(f'm_seq: {m_seq}\\n\\n')\n",
    "print(f'b_seq_pv: {b_seq_pv}\\n\\n')\n",
    "print(f'msg_seq_raw: {msg_seq_raw}\\n\\n')\n",
    "print(f'book_l2_init: {book_l2_init}\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BATCH [4497, 6855]\n",
      "\n",
      "ITERATION  1\n",
      "1: book_l2_init shape: (2, 40):\n",
      "[[884500    225 884300    400 884600    225 884200    250 884700    353\n",
      "  884100    625 884800    349 884000    325 884900    925 883900    625\n",
      "  885000   1900 883800   1122 885100    300 883700    100 885200    300\n",
      "  883600    100 885300    300 883500    100 885400    707 883400    200]\n",
      " [874900    179 874800    381 875000   1168 874700    482 875100   1738\n",
      "  874600    427 875200   1488 874500   1182 875300    510 874400   1086\n",
      "  875400   1100 874300    983 875500   1050 874200    400 875600    910\n",
      "  874100    250 875700    445 874000    557 875800   1297 873900    841]]\n",
      "\n",
      "1: m_seq_raw_inp shape: (2, 500, 14):\n",
      "[[[815620622         3         1 ...       100     53060 276711069]\n",
      "  [815626126         1         1 ...     -9999     -9999     -9999]\n",
      "  [815628422         1         0 ...     -9999     -9999     -9999]\n",
      "  ...\n",
      "  [815716726         1         0 ...     -9999     -9999     -9999]\n",
      "  [815716734         1         0 ...     -9999     -9999     -9999]\n",
      "  [815705094         3         1 ...       100     53063 100515860]]\n",
      "\n",
      " [[637822774         1         0 ...     -9999     -9999     -9999]\n",
      "  [637819270         3         1 ...       100     49828 979461959]\n",
      "  [637819102         3         1 ...       100     49828 978347552]\n",
      "  ...\n",
      "  [637994274         3         1 ...       100     49834 782338141]\n",
      "  [637994130         3         1 ...       100     49834 782005446]\n",
      "  [637994154         3         1 ...       100     49834 782047385]]]\n",
      "\n",
      "midprice after 1-th iteration and 500 generated messages = [884500 874800]\n",
      "\n",
      "AGGRESSIVE MESSAGE INSERTED - 1\n",
      "\n",
      "\n",
      "\n",
      "ITERATION  2\n",
      "2: book_l2_init shape: (2, 40):\n",
      "[[ 8.847e+05  2.500e+01  8.845e+05  2.500e+02  8.848e+05  1.500e+02\n",
      "   8.844e+05  2.500e+02  8.849e+05  6.270e+02  8.843e+05  4.500e+02\n",
      "   8.850e+05  1.725e+03  8.842e+05  5.250e+02  8.851e+05  4.000e+02\n",
      "   8.841e+05  9.250e+02  8.852e+05  6.000e+02  8.840e+05  5.000e+02\n",
      "   8.853e+05  7.000e+02  8.839e+05  2.000e+02  8.854e+05  8.070e+02\n",
      "   8.838e+05  8.220e+02 -1.000e+00  0.000e+00  8.837e+05  1.000e+02\n",
      "  -1.000e+00  0.000e+00  8.836e+05  1.000e+02]\n",
      " [ 8.748e+05  6.030e+02  8.746e+05  6.780e+02  8.749e+05  1.178e+03\n",
      "   8.745e+05  5.820e+02  8.750e+05  1.505e+03  8.744e+05  5.100e+02\n",
      "   8.751e+05  1.038e+03  8.743e+05  8.830e+02  8.752e+05  1.663e+03\n",
      "   8.742e+05  1.028e+03  8.753e+05  1.110e+03  8.741e+05  4.500e+02\n",
      "   8.754e+05  1.465e+03  8.740e+05  4.010e+02  8.755e+05  2.500e+02\n",
      "   8.739e+05  7.970e+02  8.756e+05  9.080e+02  8.738e+05  6.000e+02\n",
      "   8.757e+05  4.450e+02 -1.000e+00  0.000e+00]]\n",
      "\n",
      "2: m_seq_raw_inp shape: (2, 500, 14):\n",
      "[[[      499         1         1 ...     -9999     -9999     -9999]\n",
      "  [      498         1         1 ...     -9999     -9999     -9999]\n",
      "  [      497         1         1 ...     -9999     -9999     -9999]\n",
      "  ...\n",
      "  [        2         1         1 ...     -9999     -9999     -9999]\n",
      "  [        8         3         0 ...       100     53074 541846786]\n",
      "  [      500         1         1 ...     -9999     -9999     -9999]]\n",
      "\n",
      " [[      499         1         1 ...     -9999     -9999     -9999]\n",
      "  [      498         1         1 ...     -9999     -9999     -9999]\n",
      "  [      499         3         1 ...       100     49834 859358316]\n",
      "  ...\n",
      "  [       -2         3         1 ...       200     49838 665942818]\n",
      "  [        1         1         1 ...     -9999     -9999     -9999]\n",
      "  [      500         1         1 ...     -9999     -9999     -9999]]]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/myenv/lib/python3.12/site-packages/jax/_src/ops/scatter.py:96: FutureWarning: scatter inputs have incompatible types: cannot safely cast value from dtype=float32 to dtype=int32 with jax_numpy_dtype_promotion='standard'. In future JAX releases this will result in an error.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "m_seq_gen_doubled, b_seq_gen_doubled, msgs_decoded_doubled, l2_book_states_halved, sim_init, sim_states_init = inference.run_generation_scenario(\n",
    "    n_samples, \n",
    "    batch_size,\n",
    "    ds,\n",
    "    rng,\n",
    "    seq_len,\n",
    "    n_messages,\n",
    "    n_gen_msgs,\n",
    "    state,\n",
    "    model,\n",
    "    batchnorm,\n",
    "    v.ENCODING,\n",
    "    stock,\n",
    "    n_vol_series = 500,\n",
    "    # sim_book_levels: int = 20,\n",
    "    # sim_queue_len: int = 100,\n",
    "    # data_levels: int = 10,\n",
    "    save_folder = './data_saved/',\n",
    "    tick_size = 100,\n",
    "    sample_top_n = -1,\n",
    "    sample_all = False,\n",
    "    # Insertions variables\n",
    "    num_insertions = 20,\n",
    "    num_coolings = 20\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Order insertion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What do we receive from last generation:\n",
    "\n",
    "1. m_seq_gen_doubled, \n",
    "\n",
    "2. b_seq_gen_doubled, \n",
    "\n",
    "3. msgs_decoded_doubled, \n",
    "\n",
    "4. l2_book_states_halved, \n",
    "\n",
    "5. sim_init, \n",
    "\n",
    "6. sim_states_init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# msgs_decoded_doubled.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TIMEs_i = msgs_decoded_doubled[:, -1:, 8]\n",
    "# TIMEns_i = msgs_decoded_doubled[:, -1:, 9]\n",
    "\n",
    "# tick_size = 100\n",
    "\n",
    "# # mid_price = (l2_book_states_halved[0][0].item() + l2_book_states_halved[0][2].item()) / 2\n",
    "# mid_price = (l2_book_states_halved[:, 0] + l2_book_states_halved[:, 2]) / 2\n",
    "# mid_price = mid_price[:, None]\n",
    "\n",
    "# ORDER_ID_i = 501\n",
    "# EVENT_TYPE_i = 4\n",
    "# DIRECTION_i = 1\n",
    "# PRICE_i = mid_price\n",
    "# SIZE_i = 75\n",
    "# DTs_i = 0\n",
    "# DTns_i = 0\n",
    "\n",
    "# PRICE_REF_i = 0\n",
    "# SIZE_REF_i = 0\n",
    "# TIMEs_REF_i = 0\n",
    "# TIMEns_REF_i = 0\n",
    "\n",
    "# p_abs = mid_price + PRICE_REF_i * tick_size\n",
    "# PRICE_ABS_i = 3\n",
    "\n",
    "# batch_size = TIMEns_i.shape[0]\n",
    "\n",
    "# # 1\n",
    "# ins_msg = jnp.concatenate([\n",
    "#     jnp.full((batch_size, 1), ORDER_ID_i),\n",
    "#     jnp.full((batch_size, 1), EVENT_TYPE_i),\n",
    "#     jnp.full((batch_size, 1), DIRECTION_i),\n",
    "#     mid_price,\n",
    "#     PRICE_i,\n",
    "#     jnp.full((batch_size, 1), SIZE_i),\n",
    "#     jnp.full((batch_size, 1), DTs_i),\n",
    "#     jnp.full((batch_size, 1), DTns_i),\n",
    "#     TIMEs_i,\n",
    "#     TIMEns_i,\n",
    "#     jnp.full((batch_size, 1), PRICE_REF_i),\n",
    "#     jnp.full((batch_size, 1), SIZE_REF_i),\n",
    "#     jnp.full((batch_size, 1), TIMEs_REF_i),\n",
    "#     jnp.full((batch_size, 1), TIMEns_REF_i)\n",
    "# ], axis=1)\n",
    "\n",
    "# print(\"Batched insertion message shape:\", ins_msg.shape)  # Expected: (batch_size, 14)\n",
    "# print(type(ins_msg))\n",
    "# print(ins_msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# msg_decoded = ins_msg  # assign for clarity\n",
    "# # print(f\"msg_deco|ded shape: {msg_decoded.shape}: {msg_decoded}\\n\")\n",
    "\n",
    "# # Let's assume new_part is the first N_NEW_FIELDS tokens (you can adjust as needed)\n",
    "# new_part = msg_decoded#[:, :Message_Tokenizer.N_NEW_FIELDS]  # shape (batch_size, N_NEW_FIELDS)\n",
    "\n",
    "\n",
    "# batched_side = jnp.array([DIRECTION_i] * batch_size)\n",
    "# batched_time_s_ref = jnp.array([TIMEs_REF_i] * batch_size)  \n",
    "# batched_time_ns_ref = jnp.array([TIMEns_REF_i] * batch_size)\n",
    "# batched_EVENT_TYPE = jnp.array([EVENT_TYPE_i] * batch_size)\n",
    "# batched_quantity = jnp.array([SIZE_i] * batch_size)\n",
    "# batched_p_abs = p_abs\n",
    "# new_order_id = 999\n",
    "# batched_new_order_id = jnp.array([new_order_id] * batch_size)\n",
    "\n",
    "\n",
    "# # 2\n",
    "# batched_get_order = jax.vmap(sim_init.get_order_at_time, in_axes=(0, 0, 0, 0))\n",
    "# orig_orders = batched_get_order(sim_states_init, batched_side, batched_time_s_ref, batched_time_ns_ref) # DO WE ACTUALLY RECEIVE WHAT WE NEED?\n",
    "# # print(f\"orig_orders: {orig_orders}\\n\")\n",
    "# order_id_ref = orig_orders[:, 2]  # shape (batch_size,)\n",
    "# # print(f\"order_id_ref: {order_id_ref}\\n\")\n",
    "# order_id = jnp.where((batched_EVENT_TYPE == 2) | (batched_EVENT_TYPE == 3),\n",
    "#                      order_id_ref,\n",
    "#                      batched_new_order_id)  # shape (batch_size,)\n",
    "# # print(f\"order_id: {order_id}\\n\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# batched_EVENT_TYPE = batched_EVENT_TYPE[:, None].squeeze(-1)\n",
    "# batched_side = batched_side[:, None].squeeze(-1)\n",
    "# batched_quantity = batched_quantity[:, None].squeeze(-1)\n",
    "# order_id = order_id[:, None].squeeze(-1)\n",
    "# batched_p_abs = batched_p_abs.squeeze(-1)\n",
    "# batched_time_s = TIMEs_i.squeeze(-1)\n",
    "# batched_time_ns = TIMEns_i.squeeze(-1)\n",
    "\n",
    "\n",
    "\n",
    "# # print(f\"batched_EVENT_TYPE shape: {batched_EVENT_TYPE.shape}: {batched_EVENT_TYPE}\\n\")\n",
    "# # print(f\"batched_side shape: {batched_side.shape}: {batched_side}\\n\")\n",
    "# # print(f\"batched_quantity shape: {batched_quantity.shape}: {batched_quantity}\\n\")\n",
    "# # print(f\"batched_p_abs shape: {batched_p_abs.shape}: {batched_p_abs}\\n\")\n",
    "# # print(f\"order_id shape: {order_id.shape}: {order_id}\\n\")\n",
    "# # print(f\"batched_time_s shape: {TIMEs_i.shape}: {TIMEs_i}\\n\")\n",
    "# # print(f\"batched_time_ns shape: {TIMEns_i.shape}: {TIMEns_i}\\n\")\n",
    "\n",
    "\n",
    "\n",
    "# # 3\n",
    "# batched_construct_sim_msg = jax.vmap(inference.construct_sim_msg)\n",
    "\n",
    "# batched_sim_msg = batched_construct_sim_msg(\n",
    "#     batched_EVENT_TYPE,\n",
    "#     batched_side,\n",
    "#     batched_quantity,\n",
    "#     batched_p_abs,\n",
    "#     order_id,\n",
    "#     batched_time_s,\n",
    "#     batched_time_ns,\n",
    "# )\n",
    "\n",
    "\n",
    "# # print(f\"msg_decoded shape: {batched_sim_msg.shape}: {batched_sim_msg}\\n\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# # 4\n",
    "\n",
    "# msg_decoded = msg_decoded.at[:, PRICE_ABS_i].set(batched_p_abs) \\\n",
    "#                          .at[:, ORDER_ID_i].set(order_id)\n",
    "\n",
    "\n",
    "# dummy_msg_single = inference.construct_dummy_sim_msg()\n",
    "# dummy_msg = jnp.tile(dummy_msg_single, (batch_size, 1))\n",
    "\n",
    "\n",
    "# sim_msg, msg_decoded = jax.lax.cond(\n",
    "#     jnp.isnan(new_part).any(),\n",
    "#     lambda _: (dummy_msg, msg_decoded),\n",
    "#     lambda _: (batched_sim_msg, msg_decoded),\n",
    "#     operand=None\n",
    "# )\n",
    "\n",
    "\n",
    "# print(f\"sim_msg shape: {sim_msg.shape}: {sim_msg}\\n\")\n",
    "# print(f\"msg_decoded shape: {msg_decoded.shape}: {msg_decoded}\\n\")\n",
    "\n",
    "# msg_encoded = jax.vmap(lambda m: encoding.encode_msg(m, v.ENCODING))(msg_decoded)\n",
    "\n",
    "\n",
    "# print(f\"msg_encoded shape: {msg_encoded.shape}: {msg_encoded}\\n\")\n",
    "# print(f\"m_seq_gen_doubled shape: {m_seq_gen_doubled.shape}: {m_seq_gen_doubled}\\n\")\n",
    "\n",
    "# shift = msg_encoded.shape[1]\n",
    "# UPDATED_m_seq_gen_doubled = jnp.concatenate([m_seq_gen_doubled[:, shift:], msg_encoded], axis=1)\n",
    "\n",
    "\n",
    "# shift = msg_decoded[:, None, :].shape[1]\n",
    "# UPDATED_msgs_decoded_doubled = jnp.concatenate(\n",
    "#     [msgs_decoded_doubled[:, shift:, :], msg_decoded[:, None, :]],\n",
    "#     axis=1\n",
    "# )\n",
    "\n",
    "# print(f\"UPDATED_m_seq_gen_doubled AFTER ADDING TO THE END shape: {UPDATED_m_seq_gen_doubled.shape}: {UPDATED_m_seq_gen_doubled}\\n\")\n",
    "# print(f\"UPDATED_msgs_decoded_doubled AFTER ADDING TO THE END shape: {UPDATED_msgs_decoded_doubled.shape}: {UPDATED_msgs_decoded_doubled}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What do we receive from last generation:\n",
    "\n",
    "1. m_seq_gen_doubled - DONE\n",
    "\n",
    "2. b_seq_gen_doubled, - DONE\n",
    "\n",
    "3. msgs_decoded_doubled, - DONE\n",
    "\n",
    "4. l2_book_states_halved, - DONE\n",
    "\n",
    "5. sim_init, \n",
    "\n",
    "6. sim_states_init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(f\"b_seq_gen_doubled shape: {b_seq_gen_doubled.shape}: {b_seq_gen_doubled}\\n\")\n",
    "# print(f\"l2_book_states_halved shape: {l2_book_states_halved.shape}: {l2_book_states_halved}\\n\")\n",
    "\n",
    "# l2_state_n = 20\n",
    "\n",
    "# new_sim_state = jax.vmap(sim_init.process_order_array)(sim_states_init, sim_msg)\n",
    "# new_b_state = jax.vmap(sim_init.get_L2_state, in_axes=(0, None))(new_sim_state, l2_state_n)\n",
    "# print(f\"new_b_state shape before adding time axis: {new_b_state.shape}: {new_b_state}\\n\")\n",
    "\n",
    "\n",
    "\n",
    "# new_b_state = new_b_state[:, None, :]\n",
    "# print(f\"new_b_state shape after adding time axis: {new_b_state.shape}: {new_b_state}\\n\")\n",
    "\n",
    "\n",
    "# new_state_slice = new_b_state[:, 0, :]\n",
    "# print(f\"new_state_slice shape: {new_state_slice.shape}: {new_state_slice}\\n\")\n",
    "\n",
    "# old_last_time_step = b_seq_gen_doubled[:, -1, :]\n",
    "# print(f\"old_last_time_step shape: {old_last_time_step.shape}: {old_last_time_step}\\n\")\n",
    "\n",
    "\n",
    "# # why b_seq_gen_doubled shape: (2, 1000, 501): - why I only refresh first 80 levels - why book has 501 level??\n",
    "# updated_last_time_step = jnp.concatenate([new_state_slice, old_last_time_step[:, 80:]], axis=1)\n",
    "# print(f\"updated_last_time_step shape: {updated_last_time_step.shape}: {updated_last_time_step}\\n\")\n",
    "\n",
    "\n",
    "\n",
    "# new_b_seq = jnp.concatenate([b_seq_gen_doubled[:, 1:, :], updated_last_time_step[:, None, :]], axis=1)\n",
    "# print(f\"new_b_seq shape: {new_b_seq.shape}: {new_b_seq}\\n\")\n",
    "\n",
    "# new_l2_book_states_halved = updated_last_time_step[:, :40]\n",
    "# print(f\"new_l2_book_states_halved shape: {new_l2_book_states_halved.shape}: {new_l2_book_states_halved}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a,b,c,d = inference.insert_custom_end(m_seq_gen_doubled, b_seq_gen_doubled, msgs_decoded_doubled, l2_book_states_halved, sim_init, sim_states_init, v.ENCODING)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
