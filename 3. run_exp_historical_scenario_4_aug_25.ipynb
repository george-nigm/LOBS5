{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-04 21:56:08.418471: W external/xla/xla/service/gpu/nvptx_compiler.cc:718] The NVIDIA driver's CUDA version is 12.8 which is older than the ptxas CUDA version (12.9.41). Because the driver is older than the ptxas version, XLA is disabling parallel compilation, which may slow down compilation. You should update your NVIDIA driver or use the NVIDIA-provided CUDA forward compatibility packages.\n",
      "WARNING:absl:Type handler registry overriding type \"<class 'float'>\" collision on scalar\n",
      "WARNING:absl:Type handler registry overriding type \"<class 'bytes'>\" collision on scalar\n",
      "WARNING:absl:Type handler registry overriding type \"<class 'numpy.number'>\" collision on scalar\n",
      "2025-08-04 21:56:10.777128: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import os\n",
    "import sys\n",
    "\n",
    "os.environ[\"XLA_PYTHON_CLIENT_PREALLOCATE\"] = \"false\"\n",
    "\n",
    "import torch\n",
    "torch.multiprocessing.set_start_method('spawn')\n",
    "\n",
    "import jax\n",
    "from lob.encoding import Vocab, Message_Tokenizer\n",
    "\n",
    "from lob import inference_no_errcorr as inference\n",
    "from lob.init_train import init_train_state, load_checkpoint, load_metadata, load_args_from_checkpoint\n",
    "\n",
    "from lob import inference_no_errcorr as inference\n",
    "import lob.encoding as encoding\n",
    "import preproc as preproc\n",
    "\n",
    "import jax.numpy as jnp\n",
    "import numpy as onp\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from datetime import datetime\n",
    "import yaml\n",
    "\n",
    "import historical_scenario\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "from flax.training.train_state import TrainState\n",
    "from lob.lobster_dataloader import LOBSTER_Dataset\n",
    "import flax.linen as nn\n",
    "from typing import Any, Callable, Dict, Iterable, List, Optional, Sequence, Tuple, Union\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_args(config_file):\n",
    "\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument(\n",
    "        \"--config\",\n",
    "        type=str,\n",
    "        default=config_file,\n",
    "        help=\"Path to your YAML config file\"\n",
    "    )\n",
    "\n",
    "    # Используем parse_known_args вместо parse_args\n",
    "    args, _ = parser.parse_known_args()\n",
    "    return args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = parse_args(\"historical_scenario.yaml\")\n",
    "with open(args.config, \"r\") as f:\n",
    "    cfg = yaml.safe_load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_devices:  1\n"
     ]
    }
   ],
   "source": [
    "save_folder       = cfg[\"save_folder\"]\n",
    "batch_size        = cfg[\"batch_size\"]\n",
    "n_samples         = cfg[\"n_samples\"]\n",
    "n_gen_msgs        = cfg[\"n_gen_msgs\"]\n",
    "midprice_step_size= cfg[\"midprice_step_size\"]\n",
    "num_insertions    = cfg[\"num_insertions\"]\n",
    "num_coolings      = cfg[\"num_coolings\"]\n",
    "EVENT_TYPE_i      = cfg[\"EVENT_TYPE_i\"]\n",
    "DIRECTION_i       = cfg[\"DIRECTION_i\"]\n",
    "order_volume      = cfg[\"order_volume\"]\n",
    "bsz               = cfg[\"bsz\"]\n",
    "n_messages        = cfg[\"n_messages\"]\n",
    "book_dim          = cfg[\"book_dim\"]\n",
    "n_vol_series      = cfg[\"n_vol_series\"]\n",
    "sample_top_n      = cfg[\"sample_top_n\"]\n",
    "model_size        = cfg[\"model_size\"]\n",
    "data_dir          = cfg[\"data_dir\"]\n",
    "sample_all        = cfg[\"sample_all\"]\n",
    "stock             = cfg[\"stock\"]\n",
    "tick_size         = cfg[\"tick_size\"]\n",
    "rng_seed          = cfg[\"rng_seed\"]\n",
    "ckpt_path         = cfg[\"ckpt_path\"]\n",
    "num_devices = jax.local_device_count()\n",
    "print(f'num_devices: ', num_devices)\n",
    "\n",
    "use_sample_file  = cfg[\"use_sample_file\"]\n",
    "sample_file_path = cfg[\"sample_file_path\"]\n",
    "start_batch      = cfg[\"start_batch\"]\n",
    "end_batch        = cfg[\"end_batch\"]\n",
    "\n",
    "order_volume = cfg[\"order_volume\"]\n",
    "order_volume_ratio = cfg[\"order_volume_ratio\"]\n",
    "use_relative_volume = cfg[\"use_relative_volume\"]\n",
    "\n",
    "\n",
    "# batch_size = 4\n",
    "# n_samples = 8\n",
    "# bsz = 25\n",
    "# n_gen_msgs = 50\n",
    "# midprice_step_size = 50\n",
    "# num_insertions = 2\n",
    "# num_coolings = 2\n",
    "# EVENT_TYPE_i = 4\n",
    "# DIRECTION_i = 0\n",
    "# order_volume = 75"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "sample_indices_b250_bs4_ins15_cool35.json\n",
      "0\n",
      "125\n"
     ]
    }
   ],
   "source": [
    "print(use_sample_file)\n",
    "print(sample_file_path)\n",
    "print(start_batch)\n",
    "print(end_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading metadata from checkpoints/denim-elevator-754_czg1ss71/\n",
      "Initializing model...\n"
     ]
    }
   ],
   "source": [
    "# Load metadata and model\n",
    "print(\"Loading metadata from\", ckpt_path)\n",
    "args_ckpt = load_metadata(ckpt_path)\n",
    "print(\"Initializing model...\")\n",
    "train_state, model_cls = init_train_state(\n",
    "    args_ckpt,\n",
    "    n_classes=len(Vocab()),\n",
    "    seq_len=n_messages * Message_Tokenizer.MSG_LEN,\n",
    "    book_dim=book_dim,\n",
    "    book_seq_len=n_messages,\n",
    ")\n",
    "\n",
    "import jax\n",
    "from lob import init_train\n",
    "\n",
    "def safe_deduplicate_trainstate(state):\n",
    "    try:\n",
    "        devices = jax.devices(\"gpu\")\n",
    "    except RuntimeError:\n",
    "        devices = jax.devices(\"cpu\")\n",
    "        print(\"[INFO] GPU not available. Falling back to CPU.\")\n",
    "    else:\n",
    "        print(\"[INFO] Running on GPU.\")\n",
    "    \n",
    "    return jax.device_put(\n",
    "        jax.tree.map(lambda x: x[0], state),\n",
    "        device=devices[0]\n",
    "    )\n",
    "\n",
    "init_train.deduplicate_trainstate = safe_deduplicate_trainstate\n",
    "print(\"Loading checkpoint...\")\n",
    "ckpt = load_checkpoint(train_state, ckpt_path, train=False)\n",
    "state = ckpt[\"model\"]\n",
    "model = model_cls(training=False, step_rescale=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare RNG\n",
    "rng = jax.random.PRNGKey(rng_seed)\n",
    "\n",
    "# data directory\n",
    "data_path = Path(data_dir) / stock\n",
    "data_path.mkdir(parents=True, exist_ok=True)\n",
    "print(f\"Data directory: {data_path} ({len(list(data_path.iterdir()))} files)\")\n",
    "\n",
    "# Experiment upload folder\n",
    "exp_folder = historical_scenario.create_next_experiment_folder(save_folder)\n",
    "print(\"Experiment dir:\", exp_folder)\n",
    "with open(exp_folder / \"used_config.yaml\", \"w\") as f_out:\n",
    "    yaml.dump(cfg, f_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get dataset\n",
    "ds = inference.get_dataset(data_path, n_messages, (num_insertions + num_coolings) * n_gen_msgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ================= Experiment indexes ================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rng, rng_ = jax.random.split(rng)\n",
    "# if sample_all:\n",
    "#     sample_i = jnp.arange(\n",
    "#         len(ds) // batch_size * batch_size,\n",
    "#         dtype=jnp.int32\n",
    "#     ).reshape(-1, batch_size).tolist()\n",
    "# else:\n",
    "#     assert n_samples % batch_size == 0, 'n_samples must be divisible by batch_size'\n",
    "#     sample_i = jax.random.choice(\n",
    "#         rng_,\n",
    "#         jnp.arange(len(ds), dtype=jnp.int32),\n",
    "#         shape=(n_samples // batch_size, batch_size),\n",
    "#         replace=False\n",
    "#     ).tolist()\n",
    "# rng, rng_ = jax.random.split(rng)\n",
    "\n",
    "# print(sample_i)\n",
    "\n",
    "# filename = f\"sample_indices_b{len(sample_i)}_bs{batch_size}_ins{num_insertions}_cool{num_coolings}.json\"\n",
    "\n",
    "# # сохраняем список в файл\n",
    "# with open(filename, \"w\") as f:\n",
    "#     json.dump(sample_i, f)sassdwqeцйуйцыыыы"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ================= Scenario debugging ================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def construct_custom_msg(last_msg, current_book, sim):\n",
    "#             ORDER_ID_i = 77777777\n",
    "#             EVENT_TYPE = jnp.full((batch_size,), EVENT_TYPE_i)\n",
    "#             SIDE = jnp.full((batch_size,), DIRECTION_i)\n",
    "#             PRICE = last_msg[:, 3]  # Use previous price\n",
    "#             DISPLAY_FLAG = jnp.ones((batch_size,), dtype=jnp.int32)\n",
    "\n",
    "#             best_bid_info, best_ask_info = jax.vmap(sim.get_best_bid_and_ask_inclQuants)(current_book)\n",
    "\n",
    "#             if DIRECTION_i == 0:\n",
    "#                 best_volume = best_ask_info[:, 1]  # ← второй столбец = объём\n",
    "#             else:\n",
    "#                 best_volume = best_bid_info[:, 1]\n",
    "\n",
    "#             # Decide volume based on config flag\n",
    "#             if use_relative_volume:\n",
    "#                 SIZE = (order_volume_ratio * best_volume).astype(jnp.int32)\n",
    "#             else:\n",
    "#                 SIZE = jnp.full((batch_size,), order_volume, dtype=jnp.int32)\n",
    "\n",
    "#             print(f'SIZE: ', SIZE)\n",
    "\n",
    "#             # Ensure SIZE is within allowed limits\n",
    "#             SIZE = jnp.clip(SIZE, 1, 999999)\n",
    "\n",
    "#             zeros = jnp.zeros((batch_size,), dtype=jnp.int32)\n",
    "#             TIME_s = last_msg[:, 8]\n",
    "#             TIME_ns = last_msg[:, 9]\n",
    "\n",
    "#             msg = jnp.stack([\n",
    "#                 jnp.full((batch_size,), ORDER_ID_i),\n",
    "#                 EVENT_TYPE,\n",
    "#                 SIDE,\n",
    "#                 PRICE,\n",
    "#                 DISPLAY_FLAG,\n",
    "#                 SIZE,\n",
    "#                 zeros, zeros,\n",
    "#                 TIME_s, TIME_ns,\n",
    "#                 zeros, zeros, zeros, zeros,\n",
    "#             ], axis=1)\n",
    "\n",
    "#             return msg.astype(jnp.int32)\n",
    "\n",
    "# def run_historical_scenario(\n",
    "#         n_samples: int,\n",
    "#         batch_size: int,\n",
    "#         ds: LOBSTER_Dataset,\n",
    "#         rng: jax.dtypes.prng_key,\n",
    "#         seq_len: int,\n",
    "#         n_msgs: int,\n",
    "#         n_gen_msgs: int,\n",
    "#         train_state: TrainState,\n",
    "#         model: nn.Module,\n",
    "#         batchnorm: bool,\n",
    "#         encoder: Dict[str, Tuple[jax.Array, jax.Array]],\n",
    "#         stock_symbol: str,\n",
    "#         n_vol_series: int = 500,\n",
    "#         save_folder: str = './data_saved/',\n",
    "#         tick_size: int = 100,\n",
    "#         sample_top_n: int = -1,\n",
    "#         sample_all: bool = False,\n",
    "#         num_insertions: int = 2,\n",
    "#         num_coolings: int = 2,\n",
    "#         midprice_step_size=100,\n",
    "#         EVENT_TYPE_i = 4,\n",
    "#         DIRECTION_i = 0,\n",
    "#         order_volume = 75,\n",
    "#         use_sample_file: bool = False,\n",
    "#         sample_file_path: Optional[str] = None,\n",
    "#         start_batch: int = 0,\n",
    "#         end_batch: int = -1\n",
    "#     ):\n",
    "#     \"\"\"\n",
    "#     Manual, step-by-step scenario runner: for each batch, processes messages one at a time,\n",
    "#     updating the orderbook and tracking midprices, mimicking track_midprices_during_messages.\n",
    "#     Saves processed messages, books, and midprices for each batch.\n",
    "\n",
    "    \n",
    "#     \"\"\"\n",
    "    \n",
    "#     rng, rng_ = jax.random.split(rng)\n",
    "\n",
    "#     if use_sample_file:\n",
    "#         assert sample_file_path is not None, \"Path to sample file not provided\"\n",
    "        \n",
    "#         with open(sample_file_path, \"r\") as f:\n",
    "#             sample_i_full = json.load(f)\n",
    "\n",
    "#         sample_i = sample_i_full[start_batch:end_batch if end_batch != -1 else None]\n",
    "\n",
    "#         for i, batch in enumerate(sample_i):\n",
    "#             assert len(batch) == batch_size, f\"Batch {i} has incorrect size {len(batch)}, expected {batch_size}\"\n",
    "\n",
    "#     else:\n",
    "#         if sample_all:\n",
    "#             sample_i = jnp.arange(\n",
    "#                 len(ds) // batch_size * batch_size,\n",
    "#                 dtype=jnp.int32\n",
    "#             ).reshape(-1, batch_size).tolist()\n",
    "#         else:\n",
    "#             assert n_samples % batch_size == 0, 'n_samples must be divisible by batch_size'\n",
    "#             sample_i = jax.random.choice(\n",
    "#                 rng_,\n",
    "#                 jnp.arange(len(ds), dtype=jnp.int32),\n",
    "#                 shape=(n_samples // batch_size, batch_size),\n",
    "#                 replace=False\n",
    "#             ).tolist()\n",
    "\n",
    "#     rng, rng_ = jax.random.split(rng)\n",
    "\n",
    "    \n",
    "#     save_folder = Path(save_folder)\n",
    "#     save_folder.joinpath('msgs_decoded_doubled').mkdir(exist_ok=True, parents=True)\n",
    "#     # save_folder.joinpath('l2_book_states_halved').mkdir(exist_ok=True, parents=True)\n",
    "#     save_folder.joinpath('b_seq_gen_doubled').mkdir(exist_ok=True, parents=True)\n",
    "#     save_folder.joinpath('mid_price').mkdir(exist_ok=True, parents=True)\n",
    "#     base_save_folder = save_folder\n",
    "\n",
    "#     for batch_i in tqdm(sample_i):\n",
    "#         print('BATCH', batch_i)\n",
    "#         m_seq, _, b_seq_pv, msg_seq_raw, book_l2_init = ds[batch_i]\n",
    "#         m_seq = jnp.array(m_seq)\n",
    "#         b_seq_pv = jnp.array(b_seq_pv)\n",
    "#         msg_seq_raw = jnp.array(msg_seq_raw)\n",
    "#         book_l2_init = jnp.array(book_l2_init)\n",
    "\n",
    "#         current_book = book_l2_init\n",
    "\n",
    "#         #=============#\n",
    "#         # # Step 1: Prepare positions where to insert messages (accounting for prior insertions)\n",
    "#         insertion_points = [n_msgs + (i + 1) * n_gen_msgs + i for i in range(num_insertions)]\n",
    "#         insertion_points = [p for p in insertion_points if p <= msg_seq_raw.shape[1]]\n",
    "#         print(f\"[BATCH {batch_i}] Inserting custom messages at: {insertion_points}\")\n",
    "\n",
    "#         # # Step 2: Generate placeholder message using same logic as insert_custom_end (just 14-dim msg, no book logic yet)\n",
    "#         # def construct_custom_msg(last_msg):\n",
    "#         #     ORDER_ID_i = 77777777\n",
    "#         #     EVENT_TYPE = jnp.full((batch_size,), EVENT_TYPE_i)\n",
    "#         #     SIDE = jnp.full((batch_size,), DIRECTION_i)\n",
    "#         #     PRICE = last_msg[:, 3]  # or use fixed jnp.full((batch_size,), 123456)\n",
    "#         #     DISPLAY_FLAG = jnp.ones((batch_size,), dtype=jnp.int32)\n",
    "            \n",
    "\n",
    "#         #     #\n",
    "#         #     SIZE = jnp.full((batch_size,), order_volume) # - need to get an actual best ask/bid volume and choose min(999999, available_best_volume)\n",
    "#         #     #\n",
    "\n",
    "#         #     zeros = jnp.zeros((batch_size,), dtype=jnp.int32)\n",
    "#         #     TIME_s = last_msg[:, 8]\n",
    "#         #     TIME_ns = last_msg[:, 9]\n",
    "\n",
    "#         #     msg = jnp.stack([\n",
    "#         #         jnp.full((batch_size,), ORDER_ID_i),\n",
    "#         #         EVENT_TYPE,\n",
    "#         #         SIDE,\n",
    "#         #         PRICE,\n",
    "#         #         DISPLAY_FLAG,\n",
    "#         #         SIZE,\n",
    "#         #         zeros, zeros,\n",
    "#         #         TIME_s, TIME_ns,\n",
    "#         #         zeros, zeros, zeros, zeros,\n",
    "#         #     ], axis=1)\n",
    "\n",
    "#         #     return msg.astype(jnp.int32)\n",
    "\n",
    "        \n",
    "\n",
    "#         # Step 3: Loop and insert messages\n",
    "#         # for i, idx in enumerate(insertion_points):\n",
    "#         #     custom_msg = construct_custom_msg(msg_seq_raw[:, idx - 1])\n",
    "#         #     msg_seq_raw = jnp.concatenate([\n",
    "#         #         msg_seq_raw[:, :idx, :],\n",
    "#         #         custom_msg[:, None, :],  # shape (B, 1, 14)\n",
    "#         #         msg_seq_raw[:, idx:, :]\n",
    "#         #     ], axis=1)\n",
    "\n",
    "#         for i, idx in enumerate(insertion_points):\n",
    "#             # Simulate state before insertion\n",
    "#             msg_prev = msg_seq_raw[:, idx - 1:idx, :]\n",
    "#             sim_init, sim_state = inference.get_sims_vmap(current_book, msg_prev)\n",
    "\n",
    "#             # Construct custom message using sim state and current book\n",
    "#             custom_msg = construct_custom_msg(msg_prev[:, 0, :], sim_state, sim_init)\n",
    "\n",
    "#             # Insert the message into sequence\n",
    "#             msg_seq_raw = jnp.concatenate([\n",
    "#                 msg_seq_raw[:, :idx, :],\n",
    "#                 custom_msg[:, None, :],\n",
    "#                 msg_seq_raw[:, idx:, :]\n",
    "#             ], axis=1)\n",
    "\n",
    "#         # print(f\"[BATCH {batch_i}] msg_seq_raw shape after insertions: {msg_seq_raw.shape}\")\n",
    "#         #=============#\n",
    "\n",
    "#         batch_size, T, msg_dim = msg_seq_raw.shape\n",
    "#         current_book = book_l2_init\n",
    "\n",
    "#         books = []\n",
    "#         messages = []\n",
    "#         midprices = []\n",
    "\n",
    "#         for t in range(T):\n",
    "#             msg = msg_seq_raw[:, t:t+1, :]\n",
    "#             sim_init, sim_states = inference.get_sims_vmap(current_book, msg)\n",
    "#             mid_price = inference.batched_get_safe_mid_price(sim_init, sim_states, tick_size)\n",
    "#             full_l2_state = jax.vmap(sim_init.get_L2_state, in_axes=(0, None))(sim_states, current_book.shape[1])\n",
    "#             current_book = full_l2_state[:, : current_book.shape[1]]\n",
    "#             books.append(current_book)\n",
    "#             messages.append(msg)\n",
    "#             midprices.append(mid_price)\n",
    "\n",
    "#         books = jnp.stack(books, axis=1)             # (batch, T, book_dim)\n",
    "#         messages = jnp.concatenate(messages, axis=1) # (batch, T, msg_dim)\n",
    "#         midprices = jnp.stack(midprices, axis=0)     # (T, batch)\n",
    "\n",
    "#         # print(f\"[BATCH {batch_i}] Finished all {T} steps\")\n",
    "#         # print(f\"[BATCH {batch_i}] Final messages shape: {messages.shape}\")\n",
    "#         # print(f\"[BATCH {batch_i}] Final books shape: {books.shape}\")\n",
    "#         # print(f\"[BATCH {batch_i}] Final midprices shape: {midprices.shape}\")\n",
    "\n",
    "#         np.save(os.path.join(base_save_folder, 'msgs_decoded_doubled', f'msgs_decoded_doubled_batch_{batch_i}_iter_0.npy'), np.array(jax.device_get(messages)))\n",
    "#         # np.save(os.path.join(base_save_folder, 'l2_book_states_halved', f'l2_book_states_halved_batch_{batch_i}_iter_0.npy'), np.array(jax.device_get(books)))\n",
    "#         np.save(os.path.join(base_save_folder, 'mid_price', f'mid_price_batch_{batch_i}_iter_0.npy'), np.array(jax.device_get(midprices)))\n",
    "\n",
    "#         # ========================\n",
    "#         transform_L2_state_batch = jax.jit(jax.vmap(preproc.transform_L2_state, in_axes=(0, None, None)), static_argnums=(1, 2))\n",
    "\n",
    "#         # Get midprices for each step: (T, B) → (B, T)\n",
    "#         midprices_batched = midprices.T  # (B, T)\n",
    "#         p_mid = midprices_batched[:, :, None]  # (B, T, 1)\n",
    "\n",
    "#         # Add midprice as first column to each book state\n",
    "#         books_with_mid = jnp.concatenate([p_mid, books], axis=-1)  # (B, T, 41)\n",
    "\n",
    "#         # Transform each book+midprice into model input format\n",
    "#         books_transformed = transform_L2_state_batch(books_with_mid, n_vol_series, tick_size)  # (B, T, D)\n",
    "\n",
    "#         # Save transformed books\n",
    "#         np.save(os.path.join(base_save_folder, 'b_seq_gen_doubled', f'b_seq_gen_doubled_batch_{batch_i}_iter_0.npy'), np.array(jax.device_get(books_transformed)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def construct_custom_msg(\n",
    "    last_msg: jnp.ndarray,\n",
    "    current_book: jnp.ndarray,\n",
    "    sim_init,\n",
    "    sim_state,\n",
    "    DIRECTION_i: int,\n",
    "    EVENT_TYPE_i: int,\n",
    "    order_volume: int,\n",
    "    use_relative_volume: bool,\n",
    "    order_volume_ratio: float\n",
    ") -> jnp.ndarray:\n",
    "    \"\"\"\n",
    "    Construct a custom message (e.g., a large market order) based on the last message and current order book.\n",
    "    \"\"\"\n",
    "\n",
    "    batch_size = last_msg.shape[0]\n",
    "    ORDER_ID_i = 77777777\n",
    "\n",
    "    EVENT_TYPE = jnp.full((batch_size,), EVENT_TYPE_i, dtype=jnp.int32)\n",
    "    SIDE = jnp.full((batch_size,), DIRECTION_i, dtype=jnp.int32)\n",
    "    PRICE = last_msg[:, 3]\n",
    "    DISPLAY_FLAG = jnp.ones((batch_size,), dtype=jnp.int32)\n",
    "\n",
    "    # Correctly call per-state bid/ask info\n",
    "    best_bid_info, best_ask_info = jax.vmap(\n",
    "        lambda state: sim_init.get_best_bid_and_ask_inclQuants(state)\n",
    "    )(sim_state)\n",
    "\n",
    "    # Get price and volume from current book state\n",
    "    PRICE = jnp.where(\n",
    "        DIRECTION_i == 0,\n",
    "        best_ask_info[:, 0],  # best ask price\n",
    "        best_bid_info[:, 0]   # best bid price\n",
    "    )\n",
    "\n",
    "    best_volume = jnp.where(\n",
    "        DIRECTION_i == 0,\n",
    "        best_ask_info[:, 1],  # volume at best ask\n",
    "        best_bid_info[:, 1]   # volume at best bid\n",
    "    )\n",
    "\n",
    "    if use_relative_volume:\n",
    "        SIZE = (order_volume_ratio * best_volume).astype(jnp.int32)\n",
    "    else:\n",
    "        SIZE = jnp.full((batch_size,), order_volume, dtype=jnp.int32)\n",
    "\n",
    "    SIZE = jnp.clip(SIZE, 1, 999999)\n",
    "\n",
    "    zeros = jnp.zeros((batch_size,), dtype=jnp.int32)\n",
    "    TIME_s = last_msg[:, 8]\n",
    "    TIME_ns = last_msg[:, 9]\n",
    "\n",
    "    custom_msg = jnp.stack([\n",
    "        jnp.full((batch_size,), ORDER_ID_i, dtype=jnp.int32),\n",
    "        EVENT_TYPE,\n",
    "        SIDE,\n",
    "        PRICE,\n",
    "        DISPLAY_FLAG,\n",
    "        SIZE,\n",
    "        zeros, zeros,\n",
    "        TIME_s,\n",
    "        TIME_ns,\n",
    "        zeros, zeros, zeros, zeros\n",
    "    ], axis=1)\n",
    "\n",
    "    return custom_msg.astype(jnp.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def run_historical_scenario(\n",
    "#         n_samples: int,\n",
    "#         batch_size: int,\n",
    "#         ds: LOBSTER_Dataset,\n",
    "#         rng: jax.dtypes.prng_key,\n",
    "#         seq_len: int,\n",
    "#         n_msgs: int,\n",
    "#         n_gen_msgs: int,\n",
    "#         train_state: TrainState,\n",
    "#         model: nn.Module,\n",
    "#         batchnorm: bool,\n",
    "#         encoder: Dict[str, Tuple[jax.Array, jax.Array]],\n",
    "#         stock_symbol: str,\n",
    "#         n_vol_series: int = 500,\n",
    "#         save_folder: str = './data_saved/',\n",
    "#         tick_size: int = 100,\n",
    "#         sample_top_n: int = -1,\n",
    "#         sample_all: bool = False,\n",
    "#         num_insertions: int = 2,\n",
    "#         num_coolings: int = 2,\n",
    "#         midprice_step_size=100,\n",
    "#         EVENT_TYPE_i = 4,\n",
    "#         DIRECTION_i = 0,\n",
    "#         order_volume = 75,\n",
    "#         use_sample_file: bool = False,\n",
    "#         sample_file_path: Optional[str] = None,\n",
    "#         start_batch: int = 0,\n",
    "#         end_batch: int = -1\n",
    "#     ):\n",
    "\n",
    "\n",
    "#     rng, rng_ = jax.random.split(rng)\n",
    "\n",
    "#     if use_sample_file:\n",
    "#         assert sample_file_path is not None, \"Path to sample file not provided\"\n",
    "        \n",
    "#         with open(sample_file_path, \"r\") as f:\n",
    "#             sample_i_full = json.load(f)\n",
    "\n",
    "#         sample_i = sample_i_full[start_batch:end_batch if end_batch != -1 else None]\n",
    "\n",
    "#         for i, batch in enumerate(sample_i):\n",
    "#             assert len(batch) == batch_size, f\"Batch {i} has incorrect size {len(batch)}, expected {batch_size}\"\n",
    "\n",
    "#     else:\n",
    "#         if sample_all:\n",
    "#             sample_i = jnp.arange(\n",
    "#                 len(ds) // batch_size * batch_size,\n",
    "#                 dtype=jnp.int32\n",
    "#             ).reshape(-1, batch_size).tolist()\n",
    "#         else:\n",
    "#             assert n_samples % batch_size == 0, 'n_samples must be divisible by batch_size'\n",
    "#             sample_i = jax.random.choice(\n",
    "#                 rng_,\n",
    "#                 jnp.arange(len(ds), dtype=jnp.int32),\n",
    "#                 shape=(n_samples // batch_size, batch_size),\n",
    "#                 replace=False\n",
    "#             ).tolist()\n",
    "\n",
    "#     rng, rng_ = jax.random.split(rng)\n",
    "    \n",
    "#     save_folder = Path(save_folder)\n",
    "#     save_folder.joinpath('msgs_decoded_doubled').mkdir(exist_ok=True, parents=True)\n",
    "#     save_folder.joinpath('b_seq_gen_doubled').mkdir(exist_ok=True, parents=True)\n",
    "#     save_folder.joinpath('mid_price').mkdir(exist_ok=True, parents=True)\n",
    "    \n",
    "#     for batch_i in tqdm(sample_i):\n",
    "#         print('BATCH', batch_i)\n",
    "#         m_seq, _, b_seq_pv, msg_seq_raw, book_l2_init = ds[batch_i]\n",
    "#         msg_seq_raw = jnp.array(msg_seq_raw)\n",
    "#         book_l2_init = jnp.array(book_l2_init)\n",
    "        \n",
    "#         current_book = book_l2_init\n",
    "        \n",
    "        \n",
    "#         insertion_points = [n_msgs + (i + 1) * n_gen_msgs + i for i in range(num_insertions)]\n",
    "#         insertion_points = sorted([p for p in insertion_points if p <= msg_seq_raw.shape[1]])  \n",
    "#         print(f\"[BATCH {batch_i}] Planned insertion points at indices: {insertion_points}\")\n",
    "        \n",
    "        \n",
    "#         books = []\n",
    "#         messages = []\n",
    "#         midprices = []\n",
    "        \n",
    "        \n",
    "#         original_idx = 0\n",
    "#         steps_count = 0\n",
    "#         insertion_iter = 0\n",
    "\n",
    "        \n",
    "        \n",
    "        \n",
    "#         while original_idx < msg_seq_raw.shape[1] or insertion_iter < len(insertion_points):\n",
    "#             if insertion_iter < len(insertion_points) and steps_count == insertion_points[insertion_iter]:\n",
    "#                 if steps_count == 0:\n",
    "#                     last_msg = msg_seq_raw[:, 0, :]\n",
    "#                 else:\n",
    "#                     last_msg = messages[-1]\n",
    "#                 sim_init, sim_state = inference.get_sims_vmap(current_book, last_msg[:, None, :])\n",
    "#                 custom_msg = construct_custom_msg(\n",
    "#                     last_msg,\n",
    "#                     current_book,\n",
    "#                     sim_init,\n",
    "#                     sim_state,\n",
    "#                     DIRECTION_i=DIRECTION_i,\n",
    "#                     EVENT_TYPE_i=EVENT_TYPE_i,\n",
    "#                     order_volume=order_volume,\n",
    "#                     use_relative_volume=use_relative_volume,\n",
    "#                     order_volume_ratio=order_volume_ratio\n",
    "#                 )\n",
    "                \n",
    "                \n",
    "#                 sim_init_ins, sim_state_ins = inference.get_sims_vmap(current_book, custom_msg[:, None, :])\n",
    "                \n",
    "#                 mid_price_ins = inference.batched_get_safe_mid_price(sim_init_ins, sim_state_ins, tick_size)\n",
    "                \n",
    "#                 full_l2_state_ins = jax.vmap(sim_init_ins.get_L2_state, in_axes=(0, None))(\n",
    "#                     sim_state_ins, current_book.shape[1]\n",
    "#                 )\n",
    "#                 current_book = full_l2_state_ins[:, : current_book.shape[1]]  # update current book to new state\n",
    "                \n",
    "                \n",
    "#                 messages.append(custom_msg)\n",
    "#                 books.append(current_book)\n",
    "#                 midprices.append(mid_price_ins)\n",
    "                \n",
    "#                 steps_count += 1\n",
    "#                 insertion_iter += 1\n",
    "#                 continue\n",
    "            \n",
    "#             if original_idx < msg_seq_raw.shape[1]:\n",
    "#                 msg = msg_seq_raw[:, original_idx: original_idx + 1, :]\n",
    "#                 sim_init_hist, sim_state_hist = inference.get_sims_vmap(current_book, msg)\n",
    "#                 mid_price_hist = inference.batched_get_safe_mid_price(sim_init_hist, sim_state_hist, tick_size)\n",
    "#                 full_l2_state_hist = jax.vmap(sim_init_hist.get_L2_state, in_axes=(0, None))(\n",
    "#                     sim_state_hist, current_book.shape[1]\n",
    "#                 )\n",
    "#                 current_book = full_l2_state_hist[:, : current_book.shape[1]]\n",
    "                \n",
    "#                 messages.append(msg[:, 0, :])\n",
    "#                 books.append(current_book)\n",
    "#                 midprices.append(mid_price_hist)\n",
    "                \n",
    "#                 original_idx += 1\n",
    "#                 steps_count += 1\n",
    "#             else:\n",
    "#                 print(\"No more historical messages. Awaiting remaining insertions...\")\n",
    "#                 break\n",
    "        \n",
    "#         messages_arr = jnp.concatenate([m.reshape(m.shape[0], 1, m.shape[1]) for m in messages], axis=1)  # (batch, T_total, 14)\n",
    "#         books_arr = jnp.stack(books, axis=1)  # (batch, T_total, book_dim)\n",
    "#         midprices_arr = jnp.stack(midprices, axis=0)  # (T_total, batch)\n",
    "        \n",
    "#         np.save(save_folder / 'msgs_decoded_doubled' / f'msgs_decoded_doubled_batch_{batch_i}_iter_0.npy',\n",
    "#                 jax.device_get(messages_arr))\n",
    "#         np.save(save_folder / 'mid_price' / f'mid_price_batch_{batch_i}_iter_0.npy',\n",
    "#                 jax.device_get(midprices_arr))\n",
    "        \n",
    "#         transform_L2_state_batch = jax.jit(jax.vmap(preproc.transform_L2_state, in_axes=(0, None, None)), static_argnums=(1, 2))\n",
    "        \n",
    "#         midprices_batched = midprices_arr.T[:, :, None]\n",
    "#         books_with_mid = jnp.concatenate([midprices_batched, books_arr], axis=-1)\n",
    "#         books_transformed = transform_L2_state_batch(books_with_mid, n_vol_series, tick_size)\n",
    "        \n",
    "#         np.save(save_folder / 'b_seq_gen_doubled' / f'b_seq_gen_doubled_batch_{batch_i}_iter_0.npy',\n",
    "#                 jax.device_get(books_transformed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# results = run_historical_scenario(\n",
    "#         n_samples,\n",
    "#         batch_size,\n",
    "#         ds,\n",
    "#         rng,\n",
    "#         n_messages * Message_Tokenizer.MSG_LEN,\n",
    "#         n_messages,\n",
    "#         n_gen_msgs,\n",
    "#         state,\n",
    "#         model,\n",
    "#         args_ckpt.batchnorm,\n",
    "#         Vocab().ENCODING,\n",
    "#         stock,\n",
    "#         n_vol_series,\n",
    "#         exp_folder,\n",
    "#         tick_size,\n",
    "#         sample_top_n,\n",
    "#         sample_all,\n",
    "#         num_insertions,\n",
    "#         num_coolings,\n",
    "#         midprice_step_size,\n",
    "#         EVENT_TYPE_i,\n",
    "#         DIRECTION_i,\n",
    "#         order_volume,\n",
    "#         use_sample_file,\n",
    "#         sample_file_path,\n",
    "#         start_batch,\n",
    "#         end_batch\n",
    "#     )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ================= Shifting ================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def run_historical_scenario(\n",
    "#         n_samples: int,\n",
    "#         batch_size: int,\n",
    "#         ds: LOBSTER_Dataset,\n",
    "#         rng: jax.dtypes.prng_key,\n",
    "#         seq_len: int,\n",
    "#         n_msgs: int,\n",
    "#         n_gen_msgs: int,\n",
    "#         train_state: TrainState,\n",
    "#         model: nn.Module,\n",
    "#         batchnorm: bool,\n",
    "#         encoder: Dict[str, Tuple[jax.Array, jax.Array]],\n",
    "#         stock_symbol: str,\n",
    "#         n_vol_series: int = 500,\n",
    "#         save_folder: str = './data_saved/',\n",
    "#         tick_size: int = 100,\n",
    "#         sample_top_n: int = -1,\n",
    "#         sample_all: bool = False,\n",
    "#         num_insertions: int = 2,\n",
    "#         num_coolings: int = 2,\n",
    "#         midprice_step_size=100,\n",
    "#         EVENT_TYPE_i = 4,\n",
    "#         DIRECTION_i = 0,\n",
    "#         order_volume = 75,\n",
    "#         use_sample_file: bool = False,\n",
    "#         sample_file_path: Optional[str] = None,\n",
    "#         start_batch: int = 0,\n",
    "#         end_batch: int = -1\n",
    "#     ):\n",
    "\n",
    "\n",
    "#     rng, rng_ = jax.random.split(rng)\n",
    "\n",
    "#     if use_sample_file:\n",
    "#         assert sample_file_path is not None, \"Path to sample file not provided\"\n",
    "        \n",
    "#         with open(sample_file_path, \"r\") as f:\n",
    "#             sample_i_full = json.load(f)\n",
    "\n",
    "#         sample_i = sample_i_full[start_batch:end_batch if end_batch != -1 else None]\n",
    "\n",
    "#         for i, batch in enumerate(sample_i):\n",
    "#             assert len(batch) == batch_size, f\"Batch {i} has incorrect size {len(batch)}, expected {batch_size}\"\n",
    "\n",
    "#     else:\n",
    "#         if sample_all:\n",
    "#             sample_i = jnp.arange(\n",
    "#                 len(ds) // batch_size * batch_size,\n",
    "#                 dtype=jnp.int32\n",
    "#             ).reshape(-1, batch_size).tolist()\n",
    "#         else:\n",
    "#             assert n_samples % batch_size == 0, 'n_samples must be divisible by batch_size'\n",
    "#             sample_i = jax.random.choice(\n",
    "#                 rng_,\n",
    "#                 jnp.arange(len(ds), dtype=jnp.int32),\n",
    "#                 shape=(n_samples // batch_size, batch_size),\n",
    "#                 replace=False\n",
    "#             ).tolist()\n",
    "\n",
    "#     rng, rng_ = jax.random.split(rng)\n",
    "    \n",
    "#     save_folder = Path(save_folder)\n",
    "#     save_folder.joinpath('msgs_decoded_doubled').mkdir(exist_ok=True, parents=True)\n",
    "#     save_folder.joinpath('b_seq_gen_doubled').mkdir(exist_ok=True, parents=True)\n",
    "#     save_folder.joinpath('mid_price').mkdir(exist_ok=True, parents=True)\n",
    "    \n",
    "#     for batch_i in tqdm(sample_i):\n",
    "#         print('BATCH', batch_i)\n",
    "#         m_seq, _, b_seq_pv, msg_seq_raw, book_l2_init = ds[batch_i]\n",
    "#         msg_seq_raw = jnp.array(msg_seq_raw)\n",
    "#         book_l2_init = jnp.array(book_l2_init)\n",
    "        \n",
    "#         current_book = book_l2_init\n",
    "        \n",
    "        \n",
    "#         insertion_points = [n_msgs + (i + 1) * n_gen_msgs + i for i in range(num_insertions)]\n",
    "#         insertion_points = sorted([p for p in insertion_points if p <= msg_seq_raw.shape[1]])  \n",
    "#         print(f\"[BATCH {batch_i}] Planned insertion points at indices: {insertion_points}\")\n",
    "        \n",
    "        \n",
    "#         books = []\n",
    "#         messages = []\n",
    "#         midprices = []\n",
    "        \n",
    "        \n",
    "#         original_idx = 0\n",
    "#         steps_count = 0\n",
    "#         insertion_iter = 0\n",
    "\n",
    "        \n",
    "        \n",
    "#         shift_prices_flag = False\n",
    "#         while original_idx < msg_seq_raw.shape[1] or insertion_iter < len(insertion_points):\n",
    "#             if insertion_iter < len(insertion_points) and steps_count == insertion_points[insertion_iter]:\n",
    "#                 if steps_count == 0:\n",
    "#                     last_msg = msg_seq_raw[:, 0, :]\n",
    "#                 else:\n",
    "#                     last_msg = messages[-1]\n",
    "#                 sim_init, sim_state = inference.get_sims_vmap(current_book, last_msg[:, None, :])\n",
    "#                 custom_msg = construct_custom_msg(\n",
    "#                     last_msg,\n",
    "#                     current_book,\n",
    "#                     sim_init,\n",
    "#                     sim_state,\n",
    "#                     DIRECTION_i=DIRECTION_i,\n",
    "#                     EVENT_TYPE_i=EVENT_TYPE_i,\n",
    "#                     order_volume=order_volume,\n",
    "#                     use_relative_volume=use_relative_volume,\n",
    "#                     order_volume_ratio=order_volume_ratio\n",
    "#                 )\n",
    "                \n",
    "                \n",
    "#                 sim_init_ins, sim_state_ins = inference.get_sims_vmap(current_book, custom_msg[:, None, :])\n",
    "\n",
    "#                 best_ask_vol = current_book[:, current_book.shape[1] // 2]\n",
    "#                 if jnp.all(best_ask_vol == 0):\n",
    "#                     shift_prices_flag = True\n",
    "                \n",
    "#                 mid_price_ins = inference.batched_get_safe_mid_price(sim_init_ins, sim_state_ins, tick_size)\n",
    "                \n",
    "#                 full_l2_state_ins = jax.vmap(sim_init_ins.get_L2_state, in_axes=(0, None))(\n",
    "#                     sim_state_ins, current_book.shape[1]\n",
    "#                 )\n",
    "#                 current_book = full_l2_state_ins[:, : current_book.shape[1]]  # update current book to new state\n",
    "                \n",
    "                \n",
    "#                 messages.append(custom_msg)\n",
    "#                 books.append(current_book)\n",
    "#                 midprices.append(mid_price_ins)\n",
    "                \n",
    "#                 steps_count += 1\n",
    "#                 insertion_iter += 1\n",
    "#                 continue\n",
    "            \n",
    "#             if original_idx < msg_seq_raw.shape[1]:\n",
    "#                 msg = msg_seq_raw[:, original_idx: original_idx + 1, :]\n",
    "\n",
    "#                 if shift_prices_flag:\n",
    "#                     msg = shift_sell_prices(\n",
    "#                         msg, tick_size,\n",
    "#                         PRICE_ABS_i=3,  # replace with actual index for PRICE_ABS\n",
    "#                         DIRECTION_i=DIRECTION_i,\n",
    "#                         EVENT_TYPE_i=EVENT_TYPE_i\n",
    "#                     )\n",
    "\n",
    "\n",
    "#                 sim_init_hist, sim_state_hist = inference.get_sims_vmap(current_book, msg)\n",
    "#                 mid_price_hist = inference.batched_get_safe_mid_price(sim_init_hist, sim_state_hist, tick_size)\n",
    "#                 full_l2_state_hist = jax.vmap(sim_init_hist.get_L2_state, in_axes=(0, None))(\n",
    "#                     sim_state_hist, current_book.shape[1]\n",
    "#                 )\n",
    "#                 current_book = full_l2_state_hist[:, : current_book.shape[1]]\n",
    "                \n",
    "#                 messages.append(msg[:, 0, :])\n",
    "#                 books.append(current_book)\n",
    "#                 midprices.append(mid_price_hist)\n",
    "                \n",
    "#                 original_idx += 1\n",
    "#                 steps_count += 1\n",
    "#             else:\n",
    "#                 print(\"No more historical messages. Awaiting remaining insertions...\")\n",
    "#                 break\n",
    "        \n",
    "#         messages_arr = jnp.concatenate([m.reshape(m.shape[0], 1, m.shape[1]) for m in messages], axis=1)  # (batch, T_total, 14)\n",
    "#         books_arr = jnp.stack(books, axis=1)  # (batch, T_total, book_dim)\n",
    "#         midprices_arr = jnp.stack(midprices, axis=0)  # (T_total, batch)\n",
    "        \n",
    "#         np.save(save_folder / 'msgs_decoded_doubled' / f'msgs_decoded_doubled_batch_{batch_i}_iter_0.npy',\n",
    "#                 jax.device_get(messages_arr))\n",
    "#         np.save(save_folder / 'mid_price' / f'mid_price_batch_{batch_i}_iter_0.npy',\n",
    "#                 jax.device_get(midprices_arr))\n",
    "        \n",
    "#         transform_L2_state_batch = jax.jit(jax.vmap(preproc.transform_L2_state, in_axes=(0, None, None)), static_argnums=(1, 2))\n",
    "        \n",
    "#         midprices_batched = midprices_arr.T[:, :, None]\n",
    "#         books_with_mid = jnp.concatenate([midprices_batched, books_arr], axis=-1)\n",
    "#         books_transformed = transform_L2_state_batch(books_with_mid, n_vol_series, tick_size)\n",
    "        \n",
    "#         np.save(save_folder / 'b_seq_gen_doubled' / f'b_seq_gen_doubled_batch_{batch_i}_iter_0.npy',\n",
    "#                 jax.device_get(books_transformed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax.numpy as jnp\n",
    "\n",
    "def shift_sell_prices(msg, tick_size, PRICE_ABS_i, DIRECTION_i, EVENT_TYPE_i):\n",
    "    \"\"\"\n",
    "    Сдвигает все цены SELL (ask) сообщений на +tick_size.\n",
    "    \"\"\"\n",
    "    # копируем чтобы не портить оригинал\n",
    "    msg_shifted = msg.copy()\n",
    "\n",
    "    # mask: Execution или Limit ордера, направление = Sell (0)\n",
    "    is_relevant = (msg[..., EVENT_TYPE_i] == 1) | (msg[..., EVENT_TYPE_i] == 4)  # Limit or Execution\n",
    "    is_sell = (msg[..., DIRECTION_i] == 0)\n",
    "\n",
    "    mask = is_relevant & is_sell\n",
    "\n",
    "    msg_shifted = msg_shifted.at[..., PRICE_ABS_i].set(\n",
    "        jnp.where(mask, msg[..., PRICE_ABS_i] + tick_size, msg[..., PRICE_ABS_i])\n",
    "    )\n",
    "    return msg_shifted\n",
    "\n",
    "\n",
    "def shift_buy_prices(msg, tick_size, PRICE_ABS_i, DIRECTION_i, EVENT_TYPE_i):\n",
    "    \"\"\"\n",
    "    Сдвигает все цены BUY (bid) сообщений на +tick_size.\n",
    "    \"\"\"\n",
    "    msg_shifted = msg.copy()\n",
    "\n",
    "    # mask: Execution или Limit ордера, направление = Buy (1)\n",
    "    is_relevant = (msg[..., EVENT_TYPE_i] == 1) | (msg[..., EVENT_TYPE_i] == 4)  # Limit or Execution\n",
    "    is_buy = (msg[..., DIRECTION_i] == 1)\n",
    "\n",
    "    mask = is_relevant & is_buy\n",
    "\n",
    "    msg_shifted = msg_shifted.at[..., PRICE_ABS_i].set(\n",
    "        jnp.where(mask, msg[..., PRICE_ABS_i] + tick_size, msg[..., PRICE_ABS_i])\n",
    "    )\n",
    "    return msg_shifted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# consuming 2 levels\n",
    "\n",
    "\n",
    "def run_historical_scenario(\n",
    "        n_samples: int,\n",
    "        batch_size: int,\n",
    "        ds: LOBSTER_Dataset,\n",
    "        rng: jax.dtypes.prng_key,\n",
    "        seq_len: int,\n",
    "        n_msgs: int,\n",
    "        n_gen_msgs: int,\n",
    "        train_state: TrainState,\n",
    "        model: nn.Module,\n",
    "        batchnorm: bool,\n",
    "        encoder: Dict[str, Tuple[jax.Array, jax.Array]],\n",
    "        stock_symbol: str,\n",
    "        n_vol_series: int = 500,\n",
    "        save_folder: str = './data_saved/',\n",
    "        tick_size: int = 100,\n",
    "        sample_top_n: int = -1,\n",
    "        sample_all: bool = False,\n",
    "        num_insertions: int = 2,\n",
    "        num_coolings: int = 2,\n",
    "        midprice_step_size=100,\n",
    "        EVENT_TYPE_i = 4,\n",
    "        DIRECTION_i = 0,\n",
    "        order_volume = 75,\n",
    "        use_sample_file: bool = False,\n",
    "        sample_file_path: Optional[str] = None,\n",
    "        start_batch: int = 0,\n",
    "        end_batch: int = -1\n",
    "    ):\n",
    "\n",
    "\n",
    "    rng, rng_ = jax.random.split(rng)\n",
    "\n",
    "    if use_sample_file:\n",
    "        assert sample_file_path is not None, \"Path to sample file not provided\"\n",
    "        \n",
    "        with open(sample_file_path, \"r\") as f:\n",
    "            sample_i_full = json.load(f)\n",
    "\n",
    "        sample_i = sample_i_full[start_batch:end_batch if end_batch != -1 else None]\n",
    "\n",
    "        for i, batch in enumerate(sample_i):\n",
    "            assert len(batch) == batch_size, f\"Batch {i} has incorrect size {len(batch)}, expected {batch_size}\"\n",
    "\n",
    "    else:\n",
    "        if sample_all:\n",
    "            sample_i = jnp.arange(\n",
    "                len(ds) // batch_size * batch_size,\n",
    "                dtype=jnp.int32\n",
    "            ).reshape(-1, batch_size).tolist()\n",
    "        else:\n",
    "            assert n_samples % batch_size == 0, 'n_samples must be divisible by batch_size'\n",
    "            sample_i = jax.random.choice(\n",
    "                rng_,\n",
    "                jnp.arange(len(ds), dtype=jnp.int32),\n",
    "                shape=(n_samples // batch_size, batch_size),\n",
    "                replace=False\n",
    "            ).tolist()\n",
    "\n",
    "    rng, rng_ = jax.random.split(rng)\n",
    "    \n",
    "    save_folder = Path(save_folder)\n",
    "    save_folder.joinpath('msgs_decoded_doubled').mkdir(exist_ok=True, parents=True)\n",
    "    save_folder.joinpath('b_seq_gen_doubled').mkdir(exist_ok=True, parents=True)\n",
    "    save_folder.joinpath('mid_price').mkdir(exist_ok=True, parents=True)\n",
    "    \n",
    "    for batch_i in tqdm(sample_i):\n",
    "        print('BATCH', batch_i)\n",
    "        m_seq, _, b_seq_pv, msg_seq_raw, book_l2_init = ds[batch_i]\n",
    "        msg_seq_raw = jnp.array(msg_seq_raw)\n",
    "        book_l2_init = jnp.array(book_l2_init)\n",
    "        \n",
    "        current_book = book_l2_init\n",
    "        \n",
    "        \n",
    "        insertion_points = [n_msgs + (i + 1) * n_gen_msgs + i for i in range(num_insertions)]\n",
    "        insertion_points = sorted([p for p in insertion_points if p <= msg_seq_raw.shape[1]])  \n",
    "        print(f\"[BATCH {batch_i}] Planned insertion points at indices: {insertion_points}\")\n",
    "        \n",
    "        \n",
    "        books = []\n",
    "        messages = []\n",
    "        midprices = []\n",
    "        \n",
    "        \n",
    "        original_idx = 0\n",
    "        steps_count = 0\n",
    "        insertion_iter = 0\n",
    "\n",
    "        \n",
    "        \n",
    "        shift_ticks = 0\n",
    "        while original_idx < msg_seq_raw.shape[1] or insertion_iter < len(insertion_points):\n",
    "            if insertion_iter < len(insertion_points) and steps_count == insertion_points[insertion_iter]:\n",
    "                if steps_count == 0:\n",
    "                    last_msg = msg_seq_raw[:, 0, :]\n",
    "                else:\n",
    "                    last_msg = messages[-1]\n",
    "\n",
    "                # Агрессивный ордер: съедаем весь best ask\n",
    "                sim_init, sim_state = inference.get_sims_vmap(current_book, last_msg[:, None, :])\n",
    "                custom_msg = construct_custom_msg(\n",
    "                    last_msg,\n",
    "                    current_book,\n",
    "                    sim_init,\n",
    "                    sim_state,\n",
    "                    DIRECTION_i=DIRECTION_i,\n",
    "                    EVENT_TYPE_i=EVENT_TYPE_i,\n",
    "                    order_volume=order_volume,\n",
    "                    use_relative_volume=use_relative_volume,\n",
    "                    order_volume_ratio=order_volume_ratio\n",
    "                )\n",
    "                sim_init_ins, sim_state_ins = inference.get_sims_vmap(current_book, custom_msg[:, None, :])\n",
    "                mid_price_ins = inference.batched_get_safe_mid_price(sim_init_ins, sim_state_ins, tick_size)\n",
    "                full_l2_state_ins = jax.vmap(sim_init_ins.get_L2_state, in_axes=(0, None))(\n",
    "                    sim_state_ins, current_book.shape[1]\n",
    "                )\n",
    "                current_book = full_l2_state_ins[:, : current_book.shape[1]]\n",
    "\n",
    "                messages.append(custom_msg)\n",
    "                books.append(current_book)\n",
    "                midprices.append(mid_price_ins)\n",
    "\n",
    "                shift_ticks += 1\n",
    "\n",
    "                steps_count += 1\n",
    "                insertion_iter += 1\n",
    "                continue\n",
    "            \n",
    "            if original_idx < msg_seq_raw.shape[1]:\n",
    "                msg = msg_seq_raw[:, original_idx: original_idx + 1, :]\n",
    "\n",
    "                \n",
    "                # сдвигаем цены sell\n",
    "                msg = shift_sell_prices(\n",
    "                    msg, tick_size*shift_ticks,\n",
    "                    PRICE_ABS_i=3,\n",
    "                    DIRECTION_i=2,\n",
    "                    EVENT_TYPE_i=1\n",
    "                )\n",
    "                # сдвигаем цены buy\n",
    "                msg = shift_buy_prices(\n",
    "                    msg, tick_size*shift_ticks,\n",
    "                    PRICE_ABS_i=3,\n",
    "                    DIRECTION_i=2,\n",
    "                    EVENT_TYPE_i=1\n",
    "                )\n",
    "\n",
    "\n",
    "                sim_init_hist, sim_state_hist = inference.get_sims_vmap(current_book, msg)\n",
    "                mid_price_hist = inference.batched_get_safe_mid_price(sim_init_hist, sim_state_hist, tick_size)\n",
    "                full_l2_state_hist = jax.vmap(sim_init_hist.get_L2_state, in_axes=(0, None))(\n",
    "                    sim_state_hist, current_book.shape[1]\n",
    "                )\n",
    "                current_book = full_l2_state_hist[:, : current_book.shape[1]]\n",
    "\n",
    "                messages.append(msg[:, 0, :])\n",
    "                books.append(current_book)\n",
    "                midprices.append(mid_price_hist)\n",
    "\n",
    "                original_idx += 1\n",
    "                steps_count += 1\n",
    "            else:\n",
    "                print(\"No more historical messages. Awaiting remaining insertions...\")\n",
    "                break\n",
    "        \n",
    "        messages_arr = jnp.concatenate([m.reshape(m.shape[0], 1, m.shape[1]) for m in messages], axis=1)  # (batch, T_total, 14)\n",
    "        books_arr = jnp.stack(books, axis=1)  # (batch, T_total, book_dim)\n",
    "        midprices_arr = jnp.stack(midprices, axis=0)  # (T_total, batch)\n",
    "        \n",
    "        np.save(save_folder / 'msgs_decoded_doubled' / f'msgs_decoded_doubled_batch_{batch_i}_iter_0.npy',\n",
    "                jax.device_get(messages_arr))\n",
    "        np.save(save_folder / 'mid_price' / f'mid_price_batch_{batch_i}_iter_0.npy',\n",
    "                jax.device_get(midprices_arr))\n",
    "        \n",
    "        transform_L2_state_batch = jax.jit(jax.vmap(preproc.transform_L2_state, in_axes=(0, None, None)), static_argnums=(1, 2))\n",
    "        \n",
    "        midprices_batched = midprices_arr.T[:, :, None]\n",
    "        books_with_mid = jnp.concatenate([midprices_batched, books_arr], axis=-1)\n",
    "        books_transformed = transform_L2_state_batch(books_with_mid, n_vol_series, tick_size)\n",
    "        \n",
    "        np.save(save_folder / 'b_seq_gen_doubled' / f'b_seq_gen_doubled_batch_{batch_i}_iter_0.npy',\n",
    "                jax.device_get(books_transformed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = run_historical_scenario(\n",
    "        n_samples,\n",
    "        batch_size,\n",
    "        ds,\n",
    "        rng,\n",
    "        n_messages * Message_Tokenizer.MSG_LEN,\n",
    "        n_messages,\n",
    "        n_gen_msgs,\n",
    "        state,\n",
    "        model,\n",
    "        args_ckpt.batchnorm,\n",
    "        Vocab().ENCODING,\n",
    "        stock,\n",
    "        n_vol_series,\n",
    "        exp_folder,\n",
    "        tick_size,\n",
    "        sample_top_n,\n",
    "        sample_all,\n",
    "        num_insertions,\n",
    "        num_coolings,\n",
    "        midprice_step_size,\n",
    "        EVENT_TYPE_i,\n",
    "        DIRECTION_i,\n",
    "        order_volume,\n",
    "        use_sample_file,\n",
    "        sample_file_path,\n",
    "        start_batch,\n",
    "        end_batch\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
